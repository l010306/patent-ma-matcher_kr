# -*- coding: utf-8 -*-
"""
ìŠˆí¼ ì‚¬ì „ êµ¬ì¶• ìµœì í™” ë²„ì „ (ë‹¨ê³„2)
============================
ê¸°ëŠ¥: ìë™ ë§¤ì¹­ê³¼ ìˆ˜ë™ ê²€í†  ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ë§ˆìŠ¤í„° íšŒì‚¬ ì‚¬ì „ êµ¬ì¶•

ê°œì„ ì :
1. ë” ë‚˜ì€ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ê²€ì¦
2. ì¶©ëŒ ê°ì§€ ë° ë³´ê³ 
3. ìƒì„¸í•œ ë¡œê·¸ ê¸°ë¡
4. í†µê³„ ì •ë³´ ì¶œë ¥
"""

import pandas as pd
import os
import pickle
import logging
from datetime import datetime

# ==========================================
# ë¡œê·¸ ì„¤ì •
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'dict_building_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# 1. ì„¤ì •: ì…ë ¥ íŒŒì¼ ëª©ë¡
# ==========================================
# ì—¬ëŸ¬ ì—°ë„ íŒŒì¼ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë©°, í•„ìš”ì— ë”°ë¼ ì¶”ê°€
FILES_TO_PROCESS = [
    # --- 1993-1997ë…„ íŒŒì¼ ---
    'Step1_Manual_Review.xlsx',      # ìˆ˜ë™ ê²€í†  í›„ íŒŒì¼ (ì˜¤ë¥˜ ë§¤ì¹­ ì œê±°)
    'Step1_Auto_Results.xlsx',       # ìë™ ë§¤ì¹­ ê²°ê³¼
    
    # --- ë‹¤ë¥¸ ì—°ë„ê°€ ìˆìœ¼ë©´ ì—¬ê¸°ì— ì¶”ê°€ ---
    # '1998_2000_Manual_Review.xlsx',
    # '1998_2000_Auto_Results.xlsx',

]

# ì¶œë ¥ íŒŒì¼ ì„¤ì •
OUTPUT_DICT_FILE = 'Master_Company_Dictionary.pkl'       # ì½”ë“œ ë¡œë”©ìš© (Pickle í˜•ì‹)
OUTPUT_EXCEL_FILE = 'Master_Company_Dictionary_VIEW.xlsx' # ìˆ˜ë™ í™•ì¸ìš© (Excel í˜•ì‹)

# ==========================================
# 2. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================

def build_master_dictionary(files_list):
    """
    ìŠˆí¼ ì‚¬ì „ êµ¬ì¶•
    ë°˜í™˜: master_dict, statistics
    """
    logger.info("=" * 60)
    logger.info("ìŠˆí¼ ì‚¬ì „ êµ¬ì¶• ì‹œì‘ (ë§ˆìŠ¤í„° íšŒì‚¬ ì‚¬ì „)")
    logger.info("=" * 60)
    
    master_dict = {}  # êµ¬ì¡°: { 'Assignee_Original': 'Original_Acquiror_Name' }
    source_stats = []
    conflicts = []  # ì¶©ëŒ ê¸°ë¡
    
    for file_path in files_list:
        if not os.path.exists(file_path):
            logger.warning(f"âš ï¸  ê±´ë„ˆë›°ê¸°: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ {file_path}")
            continue
        
        logger.info(f"\nì²˜ë¦¬ ì¤‘: {file_path}")
        
        try:
            df = pd.read_excel(file_path)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['Assignee_Original', 'Original_Acquiror_Name']
            if not all(col in df.columns for col in required_cols):
                logger.error(f"   âŒ ì˜¤ë¥˜: í•„ìˆ˜ ì»¬ëŸ¼ {required_cols} ëˆ„ë½, ì´ íŒŒì¼ ê±´ë„ˆë›°ê¸°")
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ í•„í„°ë§
            df_valid = df.dropna(subset=required_cols)
            df_valid = df_valid[
                (df_valid['Assignee_Original'].astype(str).str.strip() != "") &
                (df_valid['Original_Acquiror_Name'].astype(str).str.strip() != "")
            ]
            
            logger.info(f"   ìœ íš¨ í–‰ ìˆ˜: {len(df_valid)}")
            
            # í†µê³„ ì •ë³´
            count_new = 0
            count_duplicate = 0
            count_conflict = 0
            
            for idx, row in df_valid.iterrows():
                assignee_raw = str(row['Assignee_Original']).strip()
                acquiror_std = str(row['Original_Acquiror_Name']).strip()
                
                if assignee_raw not in master_dict:
                    # ìƒˆ ë§¤í•‘
                    master_dict[assignee_raw] = acquiror_std
                    count_new += 1
                else:
                    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë§¤í•‘
                    existing = master_dict[assignee_raw]
                    if existing == acquiror_std:
                        # ì¤‘ë³µì´ì§€ë§Œ ì¼ì¹˜
                        count_duplicate += 1
                    else:
                        # ì¶©ëŒ!
                        count_conflict += 1
                        conflicts.append({
                            'Assignee': assignee_raw,
                            'Existing_Acquiror': existing,
                            'New_Acquiror': acquiror_std,
                            'Source_File': file_path
                        })
                        # ì „ëµ: ì²« ë²ˆì§¸ ë§¤í•‘ ìœ ì§€, ì¶©ëŒ ê¸°ë¡
                        logger.warning(f"   âš ï¸  ì¶©ëŒ: '{assignee_raw}'ì€ ì´ë¯¸ '{existing}'ë¡œ ë§¤í•‘ë¨, ìƒˆ ê°’ '{acquiror_std}' ë¬´ì‹œë¨")
            
            logger.info(f"   âœ… ì²˜ë¦¬ ì™„ë£Œ: ì‹ ê·œ {count_new}, ì¤‘ë³µ {count_duplicate}, ì¶©ëŒ {count_conflict}")
            
            source_stats.append({
                'File': os.path.basename(file_path),
                'Valid_Rows': len(df_valid),
                'New_Mappings': count_new,
                'Duplicates': count_duplicate,
                'Conflicts': count_conflict
            })
            
        except Exception as e:
            logger.error(f"   âŒ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    return master_dict, source_stats, conflicts


def save_dictionary(master_dict, source_stats, conflicts):
    """ì‚¬ì „ ë° í†µê³„ ì •ë³´ ì €ì¥"""
    logger.info("\n" + "=" * 60)
    logger.info("ê²°ê³¼ ì €ì¥")
    logger.info("=" * 60)
    
    if not master_dict:
        logger.error("âŒ ì˜¤ë¥˜: ì‚¬ì „ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ë§¤í•‘ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    # 1. Pickleë¡œ ì €ì¥ (í›„ì† ì½”ë“œ ë¡œë”©ìš©)
    with open(OUTPUT_DICT_FILE, 'wb') as f:
        pickle.dump(master_dict, f)
    logger.info(f"âœ… Pickle íŒŒì¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_DICT_FILE}")
    
    # 2. Excelë¡œ ì €ì¥ (ìˆ˜ë™ í™•ì¸ìš©)
    df_out = pd.DataFrame(
        list(master_dict.items()), 
        columns=['Assignee_Original_Name', 'Mapped_Acquiror_Name']
    )
    df_out = df_out.sort_values('Mapped_Acquiror_Name').reset_index(drop=True)
    df_out.to_excel(OUTPUT_EXCEL_FILE, index=False)
    logger.info(f"âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_EXCEL_FILE}")
    
    # 3. í†µê³„ ì •ë³´ ì €ì¥
    if source_stats:
        df_stats = pd.DataFrame(source_stats)
        stats_file = 'Dictionary_Build_Statistics.xlsx'
        df_stats.to_excel(stats_file, index=False)
        logger.info(f"âœ… í†µê³„ ì •ë³´ ì €ì¥ ì™„ë£Œ: {stats_file}")
    
    # 4. ì¶©ëŒì´ ìˆìœ¼ë©´ ì¶©ëŒ ë³´ê³ ì„œ ì €ì¥
    if conflicts:
        df_conflicts = pd.DataFrame(conflicts)
        conflict_file = 'Dictionary_Conflicts.xlsx'
        df_conflicts.to_excel(conflict_file, index=False)
        logger.warning(f"âš ï¸  ì¶©ëŒ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {conflict_file} ({len(conflicts)} ê±´ ì¶©ëŒ)")
    
    return True


def print_summary(master_dict, source_stats, conflicts):
    """ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    logger.info("\n" + "=" * 60)
    logger.info("êµ¬ì¶• ì™„ë£Œ ìš”ì•½")
    logger.info("=" * 60)
    
    logger.info(f"\nğŸ“Š ì „ì²´ í†µê³„:")
    logger.info(f"   - ì´ ë§¤í•‘ ê´€ê³„ ìˆ˜: {len(master_dict):,}")
    logger.info(f"   - ì²˜ë¦¬í•œ íŒŒì¼ ìˆ˜: {len(source_stats)}")
    logger.info(f"   - ê°ì§€ëœ ì¶©ëŒ: {len(conflicts)}")
    
    if source_stats:
        logger.info(f"\nğŸ“ ê° íŒŒì¼ ê¸°ì—¬ë„:")
        for stat in source_stats:
            logger.info(f"   {stat['File']}")
            logger.info(f"      ì‹ ê·œ: {stat['New_Mappings']}, ì¤‘ë³µ: {stat['Duplicates']}, ì¶©ëŒ: {stat['Conflicts']}")
    
    # ë™ì¼ íšŒì‚¬ì— ë§¤í•‘ëœ ë³€í˜• ìˆ˜ í†µê³„
    from collections import Counter
    acquiror_counts = Counter(master_dict.values())
    top_companies = acquiror_counts.most_common(10)
    
    logger.info(f"\nğŸ¢ ê°€ì¥ ë§ì€ ë³€í˜•ì„ ê°€ì§„ íšŒì‚¬ (ìƒìœ„ 10):")
    for company, count in top_companies:
        logger.info(f"   {company}: {count} ê°œ ë³€í˜•")
    
    if conflicts:
        logger.info(f"\nâš ï¸  ê²½ê³ : {len(conflicts)} ê°œ ì¶©ëŒ ë°œê²¬, Dictionary_Conflicts.xlsx í™•ì¸ í•„ìš”")
        logger.info("   ì¶©ëŒ ì²˜ë¦¬ ì „ëµ: ì²« ë§¤í•‘ ìœ ì§€")


# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤
# ==========================================

def main():
    start_time = datetime.now()
    
    # ì‚¬ì „ êµ¬ì¶•
    master_dict, source_stats, conflicts = build_master_dictionary(FILES_TO_PROCESS)
    
    # ê²°ê³¼ ì €ì¥
    success = save_dictionary(master_dict, source_stats, conflicts)
    
    if success:
        # ìš”ì•½ ì¶œë ¥
        print_summary(master_dict, source_stats, conflicts)
        
        # ì†Œìš” ì‹œê°„ ê³„ì‚°
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"\nâ±  ì´ ì†Œìš”ì‹œê°„: {duration:.2f} ì´ˆ")
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ ìŠˆí¼ ì‚¬ì „ êµ¬ì¶• ì„±ê³µ!")
        logger.info("=" * 60)
        logger.info(f"\në‹¤ìŒ ë‹¨ê³„:")
        logger.info(f"   1. {OUTPUT_EXCEL_FILE} í™•ì¸í•˜ì—¬ ë§¤í•‘ ê´€ê³„ ê²€ì¦")
        logger.info(f"   2. ì¶©ëŒì´ ìˆìœ¼ë©´ Dictionary_Conflicts.xlsx ê²€í† ")
        logger.info(f"   3. ë‹¨ê³„3(ìµœì¢… ì§‘ê³„) ì‹¤í–‰í•˜ì—¬ ì´ ì‚¬ì „ ì‚¬ìš©")
        
        return True
    else:
        logger.error("\nâŒ ì‚¬ì „ êµ¬ì¶• ì‹¤íŒ¨")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
