# -*- coding: utf-8 -*-
"""
Compustat ë§¤ì¹­ - ë‹¨ê³„4A: ê²€ì¦ íŒŒì¼ ìƒì„± (ìµœì í™” ë²„ì „)
================================================
ê¸°ëŠ¥: final_outcomeì„ Compustatì™€ ë§¤ì¹­í•˜ì—¬ ìˆ˜ë™ ê²€ì¦ íŒŒì¼ ìƒì„±

ê°œì„ ì :
1. thefuzzë¥¼ rapidfuzzë¡œ ëŒ€ì²´ (ë” ë¹ ë¦„)
2. ìƒì„¸í•œ ë¡œê·¸ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
3. ê°œì„ ëœ ì •ë¦¬ í•¨ìˆ˜ (ë‹¨ê³„1ê³¼ ì¼ì¹˜)
"""

import pandas as pd
import re
from rapidfuzz import process, fuzz
from tqdm import tqdm
import logging
from datetime import datetime

# ==========================================
# ë¡œê·¸ ì„¤ì •
# ==========================================
# logs í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
import os
if not os.path.exists('logs'):
    os.makedirs('logs')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/compustat_match_4A_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# 1. ê²½ë¡œ ë° ì„¤ì •
# ==========================================
PATH_MA = "/Users/lidachuan/Desktop/Patent Data/final_outcome_1993_1997_COMPLETE.xlsx"
PATH_COMPUSTAT = "/Users/lidachuan/Desktop/Patent Data/compustat_19802025.csv"
OUTPUT_VERIFICATION = "/Users/lidachuan/Desktop/Patent Data/company_match_verification.xlsx"

FUZZY_THRESHOLD = 90  # í¼ì§€ ë§¤ì¹­ ì„ê³„ê°’

# ==========================================
# 2. ì •ë¦¬ í•¨ìˆ˜ (ë‹¨ê³„1ê³¼ ì¼ì¹˜ ìœ ì§€)
# ==========================================

def clean_company_name(name):
    """ìµœì í™”ëœ í‘œì¤€í™” ì •ë¦¬ í•¨ìˆ˜"""
    if pd.isna(name) or not isinstance(name, str):
        return ""
    
    name = str(name).upper().strip()
    
    # 1. ì¼ë°˜ì ì¸ ê¸°í˜¸ ì²˜ë¦¬
    name = name.replace('&', ' AND ')
    name = name.replace('-', ' ')
    name = name.replace("'", '')
    
    # 2. ì¼ë°˜ì ì¸ ì•½ì–´ í™•ì¥
    abbreviations = {
        r'\bINTL\b': 'INTERNATIONAL',
        r'\bNATL\b': 'NATIONAL',
        r'\bCORP\b': 'CORPORATION',
        r'\bINC\b': 'INCORPORATED',
        r'\bMFG\b': 'MANUFACTURING',
        r'\bTECH\b': 'TECHNOLOGY',
        r'\bSYS\b': 'SYSTEMS',
    }
    for abbr, full in abbreviations.items():
        name = re.sub(abbr, full, name)
    
    # 3. ì ‘ë¯¸ì‚¬ ì œê±°
    suffixes_priority = [
        r'\bINCORPORATED\b', r'\bCORPORATION\b', r'\bCOMPANY\b',
        r'\bLIMITED\b', r'\bGROUP\b',
        r'\bCORP\.?\b', r'\bINC\.?\b', r'\bLTD\.?\b', 
        r'\bCO\.?\b', r'\bL\.L\.C\.?\b', r'\bPLC\.?\b',
        r'\bLLC\b', r'\bS\.A\.\b', r'\bNV\b', r'\bGMBH\b',
        r'\bSA\b', r'\bAG\b', r'\bKK\b'
    ]
    
    for suffix in suffixes_priority:
        name = re.sub(suffix, '', name, flags=re.IGNORECASE)
    
    # 4. êµ¬ë‘ì  ì œê±°
    name = re.sub(r'[^A-Z0-9\s]', ' ', name)
    
    # 5. ê³µë°± ë³‘í•©
    name = re.sub(r'\s+', ' ', name).strip()
    
    return name


# ==========================================
# 3. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================

def main():
    start_time = datetime.now()
    
    logger.info("=" * 60)
    logger.info("Compustat ë§¤ì¹­ - ë‹¨ê³„4A: ê²€ì¦ íŒŒì¼ ìƒì„± (ìµœì í™” ë²„ì „)")
    logger.info("=" * 60)
    
    # ========== ë‹¨ê³„1: ë°ì´í„° ë¡œë“œ ==========
    logger.info("\në‹¨ê³„ 1/4: ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # M&A ë°ì´í„° ì½ê¸°
    logger.info("   M&A ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        df_ma = pd.read_excel(PATH_MA)
        logger.info(f"   âœ… M&A ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df_ma):,} í–‰")
    except Exception as e:
        logger.error(f"   âŒ ì½ê¸° ì‹¤íŒ¨: {e}")
        return False
    
    # í•„í„°ë§: patent_nameì´ ìˆëŠ” í–‰ë§Œ ì²˜ë¦¬
    df_ma_target = df_ma[df_ma['patent_name'].notna()].copy()
    logger.info(f"   patent_name ë¹„ì–´ìˆì§€ ì•ŠìŒìœ¼ë¡œ í•„í„°ë§: {len(df_ma_target):,} í–‰ ë§¤ì¹­ ëŒ€ê¸°")
    
    # Compustat ë°ì´í„° ì½ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ conm ì»¬ëŸ¼ë§Œ)
    logger.info("   Compustat ë°ì´í„° ë¡œë“œ ì¤‘ (íšŒì‚¬ëª… ì»¬ëŸ¼ë§Œ)...")
    try:
        # ì „ëµ: ëŒ€ìš©ëŸ‰ íŒŒì¼ì˜ ê²½ìš° í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸° (conm)
        df_comp = pd.read_csv(PATH_COMPUSTAT, usecols=['conm'], low_memory=False)
        logger.info(f"   âœ… Compustat ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df_comp):,} í–‰")
    except ValueError:
        # ì»¬ëŸ¼ëª…ì´ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ì½ê¸° ì‹œë„ (ëŠë¦´ ìˆ˜ ìˆìŒ)
        logger.warning("   'conm' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì „ì²´ ì½ê¸° ì‹œë„...")
        df_comp = pd.read_csv(PATH_COMPUSTAT, low_memory=False)
        logger.info(f"   âœ… Compustat ë°ì´í„° ë¡œë“œ ì„±ê³µ (ì „ì²´): {len(df_comp):,} í–‰")
    except Exception as e:
        logger.error(f"   âŒ ì½ê¸° ì‹¤íŒ¨: {e}")
        return False
    
    # ========== ë‹¨ê³„2: ë°ì´í„° ì •ë¦¬ ==========
    logger.info("\në‹¨ê³„ 2/4: íšŒì‚¬ëª… ì •ë¦¬ ì¤‘...")
    
    # M&Aì˜ acquiror_name ì •ë¦¬
    df_ma_target['clean_acquiror'] = df_ma_target['acquiror_name'].apply(clean_company_name)
    
    # Compustatì˜ conm ì •ë¦¬
    df_comp['clean_conm'] = df_comp['conm'].apply(clean_company_name)
    
    # Compustat ì¡°íšŒ ì„¸íŠ¸ ìƒì„±
    compustat_unique = df_comp[df_comp['clean_conm'] != ""][['conm', 'clean_conm']].drop_duplicates(subset=['clean_conm'])
    compustat_clean_set = set(compustat_unique['clean_conm'])
    compustat_clean_list = list(compustat_unique['clean_conm'])
    
    logger.info(f"   âœ… Compustat ê³ ìœ  íšŒì‚¬ëª…: {len(compustat_clean_list):,}")
    
    # ========== ë‹¨ê³„3: ë§¤ì¹­ ìˆ˜í–‰ ==========
    logger.info("\në‹¨ê³„ 3/4: ë§¤ì¹­ ìˆ˜í–‰ ì¤‘...")
    
    strict_res = []
    fuzzy_res = []
    unmatched_rows = []
    
    # 3.1 ì •í™• ë§¤ì¹­
    logger.info("   ë‹¨ê³„ 3.1: ì •í™• ë§¤ì¹­...")
    for idx, row in df_ma_target.iterrows():
        acquiror_orig = row['acquiror_name']
        acquiror_clean = row['clean_acquiror']
        
        if not acquiror_clean:
            continue
        
        if acquiror_clean in compustat_clean_set:
            strict_res.append({
                'Acquiror_Original': acquiror_orig,
                'Acquiror_Clean': acquiror_clean,
                'Matched_Compustat_Clean': acquiror_clean,
                'Match_Type': 'Strict',
                'Score': 100
            })
        else:
            unmatched_rows.append(row)
    
    logger.info(f"   âœ… ì •í™• ë§¤ì¹­: {len(strict_res)} ê±´")
    logger.info(f"   í¼ì§€ ë§¤ì¹­ ëŒ€ê¸°: {len(unmatched_rows)} ê±´")
    
    # 3.2 í¼ì§€ ë§¤ì¹­
    if len(unmatched_rows) > 0:
        logger.info(f"   ë‹¨ê³„ 3.2: í¼ì§€ ë§¤ì¹­ (ì„ê³„ê°’ {FUZZY_THRESHOLD})...")
        
        for row in tqdm(unmatched_rows, desc="   ë§¤ì¹­ ì§„í–‰"):
            acquiror_orig = row['acquiror_name']
            acquiror_clean = row['clean_acquiror']
            
            match_result = process.extractOne(
                acquiror_clean, 
                compustat_clean_list, 
                scorer=fuzz.token_set_ratio,
                score_cutoff=FUZZY_THRESHOLD
            )
            
            if match_result:
                match_name, score, _ = match_result
                fuzzy_res.append({
                    'Acquiror_Original': acquiror_orig,
                    'Acquiror_Clean': acquiror_clean,
                    'Matched_Compustat_Clean': match_name,
                    'Match_Type': 'Fuzzy',
                    'Score': score
                })
        
        logger.info(f"   âœ… í¼ì§€ ë§¤ì¹­: {len(fuzzy_res)} ê±´")
    
    # ========== ë‹¨ê³„4: ê²€ì¦ íŒŒì¼ ìƒì„± ==========
    logger.info("\në‹¨ê³„ 4/4: ìˆ˜ë™ ê²€ì¦ íŒŒì¼ ìƒì„± ì¤‘...")
    
    # ê²°ê³¼ ë³‘í•©
    df_strict = pd.DataFrame(strict_res)
    df_fuzzy = pd.DataFrame(fuzzy_res)
    df_all_matches = pd.concat([df_strict, df_fuzzy], ignore_index=True)
    
    if df_all_matches.empty:
        logger.warning("   âš ï¸  ì¼ì¹˜í•˜ëŠ” ê²°ê³¼ ì—†ìŒ")
        return False
    
    # Compustat ì›ë³¸ ì´ë¦„ ì°¾ê¸°
    clean_to_original_map = dict(zip(compustat_unique['clean_conm'], compustat_unique['conm']))
    df_all_matches['Matched_Compustat_Original'] = df_all_matches['Matched_Compustat_Clean'].map(clean_to_original_map)
    
    # ì¶œë ¥ ì»¬ëŸ¼ ì„ íƒ
    output_columns = [
        'Acquiror_Original',
        'Matched_Compustat_Original',
        'Match_Type',
        'Score',
        'Acquiror_Clean',
        'Matched_Compustat_Clean'
    ]
    
    df_verify = df_all_matches[output_columns].copy()
    
    # ì •ë ¬: Fuzzyê°€ ë¨¼ì €, ì ìˆ˜ê°€ ë‚®ì€ ê²ƒ ìš°ì„  ê²€í† 
    df_verify.sort_values(by=['Match_Type', 'Score'], ascending=[True, True], inplace=True)
    
    # ë‚´ë³´ë‚´ê¸°
    df_verify.to_excel(OUTPUT_VERIFICATION, index=False)
    
    # ========== ì™„ë£Œ ìš”ì•½ ==========
    duration = (datetime.now() - start_time).total_seconds()
    
    logger.info("\n" + "=" * 60)
    logger.info("ë‹¨ê³„4A ì™„ë£Œ!")
    logger.info("=" * 60)
    logger.info(f"â±  ì´ ì†Œìš”ì‹œê°„: {duration:.2f} ì´ˆ")
    logger.info(f"ğŸ“Š ë§¤ì¹­ ê²°ê³¼:")
    logger.info(f"   - ì •í™• ë§¤ì¹­: {len(strict_res)}")
    logger.info(f"   - í¼ì§€ ë§¤ì¹­: {len(fuzzy_res)}")
    logger.info(f"   - ì´ê³„: {len(df_verify):,} ìŒ")
    logger.info(f"\nğŸ“ ì¶œë ¥ íŒŒì¼:")
    logger.info(f"   {OUTPUT_VERIFICATION}")
    logger.info(f"\nâš ï¸  ë‹¤ìŒ ë‹¨ê³„ (ì¤‘ìš”):")
    logger.info(f"   1. {OUTPUT_VERIFICATION} ì—´ê¸°")
    logger.info(f"   2. ìˆ˜ë™ ê²€í† , ì˜ëª»ëœ ë§¤ì¹­ í–‰ ì‚­ì œ")
    logger.info(f"   3. íŒŒì¼ ì €ì¥ (íŒŒì¼ëª… ìœ ì§€)")
    logger.info(f"   4. ë‹¨ê³„4B ì‹¤í–‰ (CompustatåŒ¹é…_ë‹¨ê³„4B_ìµœì í™”ë²„ì „.py)")
    logger.info("=" * 60)
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
